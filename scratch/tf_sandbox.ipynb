{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borrowed heavily from: https://github.com/nvmoyar/autoencoders/blob/master/Convolutional_Autoencoder_MNIST.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = i+1\n",
    "print(\"i:\", i)\n",
    "img = mnist.train.images[i]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "print(mnist.train.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x16\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "# Now 14x14x16\n",
    "conv2 = tf.layers.conv2d(maxpool1, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x8\n",
    "#maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "encoded = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "# Now 7x7x8\n",
    "#conv3 = tf.layers.conv2d(maxpool2, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x8\n",
    "#encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')\n",
    "# Now 4x4x8\n",
    "\n",
    "\n",
    "#Need some kinda of compression step here...\n",
    "\n",
    "\n",
    "\n",
    "### Decoder\n",
    "#upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "# Now 7x7x8\n",
    "#conv4 = tf.layers.conv2d(upsample1, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x8\n",
    "#upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "upsample2 = tf.image.resize_nearest_neighbor(encoded, (14,14))\n",
    "# Now 14x14x8\n",
    "conv5 = tf.layers.conv2d(upsample2, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x8\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "# Now 28x28x8\n",
    "conv6 = tf.layers.conv2d(upsample3, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x16\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding='same', activation=None)\n",
    "#Now 28x28x1\n",
    "\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "batch_size = 200\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    print(mnist.train.num_examples//batch_size, \"batches\")\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        if ii%50==0: print(\"Epoch: {}/{}, batch {}...\".format(e+1, epochs, ii), \n",
    "                           \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: in_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([in_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_stuff = sess.run(encoded, feed_dict={inputs_: in_imgs.reshape((10, 28, 28, 1))})\n",
    "plt.hist(np.log(encoded_stuff[6].flatten() + 0.1), bins=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow([[x[3] for x in xx] for xx in encoded_stuff[9]], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7*7*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(in_imgs[1].reshape(28, 28), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_stuff[0].flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "sess.run(decoded, feed_dict = {encoded: encoded_stuff})[1].reshape(28, 28), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Freeze the Compressed images...\n",
    "WIP..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_files = sess.run(encoded, feed_dict = {inputs_: mnist.train.images.reshape(60000,28,28,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_test = sess.run(encoded, feed_dict = {inputs_: mnist.test.images.reshape(10000,28,28,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_files.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now train component 3 (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_comp_ = tf.placeholder(tf.float32, (None, 7, 7, 8), name='inputs_comp')\n",
    "targets_lab_ = tf.placeholder(tf.int32, (None), name='targets_lab')\n",
    "\n",
    "### Decoder\n",
    "#upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "# Now 7x7x8\n",
    "#conv4 = tf.layers.conv2d(upsample1, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x8\n",
    "#upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "flat1 = tf.layers.flatten(inputs_comp_)\n",
    "#dense1 = tf.layers.dense(flat1, 128, activation=tf.nn.relu)\n",
    "# Now 1*128\n",
    "drop1 = tf.layers.dropout(flat1, rate = 0.5)\n",
    "dense2 = tf.layers.dense(drop1, 64, activation=tf.nn.relu)\n",
    "# Now 1*64\n",
    "drop2 = tf.layers.dropout(dense2, rate = 0.5)\n",
    "final = tf.layers.dense(drop2, 10, activation=tf.nn.softmax)\n",
    "# 1*10\n",
    "\n",
    "one_hot_labs = tf.one_hot(targets_lab_,10)\n",
    "\n",
    "#loss1 = tf.nn.sigmoid_cross_entropy_with_logits(labels=one_hot_labs, logits=final)\n",
    "loss1 = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_labs, logits=final)\n",
    "cost1 = tf.reduce_mean(loss1)\n",
    "opt1 = tf.train.AdamOptimizer(0.001).minimize(cost1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 200\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(mnist.train.num_examples//batch_size, \"batches\")\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        imgs = compressed_files[ii*batch_size : (ii+1)*batch_size]\n",
    "        labs = mnist.train.labels[ii*batch_size : (ii+1)*batch_size]\n",
    "        #print(labs.shape)\n",
    "        #imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        batch_cost, _ = sess.run([cost1, opt1], feed_dict={inputs_comp_: imgs,\n",
    "                                                         targets_lab_: labs})\n",
    "\n",
    "        if ii%50==0: print(\"Epoch: {}/{}, batch {}...\".format(e+1, epochs, ii), \n",
    "                           \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = sess.run(final, feed_dict = {inputs_comp_: compressed_files})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_cat = [x.argmax() for x in train_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_preds_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just looking at frequencies, maybe in sample is good, but test predictions are AWFUL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(train_preds_cat == mnist.train.labels)/len(train_preds_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test accuracy (spoiler: bad):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = sess.run(final, feed_dict = {inputs_comp_: compressed_test})\n",
    "test_preds_cat = [x.argmax() for x in test_preds]\n",
    "sum(test_preds_cat == mnist.test.labels)/len(test_preds_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_preds_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get an end-to-end classifier working first\n",
    "\n",
    "Architecture based loosely on this: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_lab_ = tf.placeholder(tf.int32, (None), name='targets_lab')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x16\n",
    "#conv2 = tf.layers.conv2d(conv1, 64, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "# Now 14x14x16\n",
    "drop1 = tf.layers.dropout(maxpool1, rate = 0.25)\n",
    "\n",
    "conv2 = tf.layers.conv2d(drop1, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x8\n",
    "maxpool1 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "# Now 7x7x8\n",
    "\n",
    "flat1 = tf.layers.flatten(maxpool1)\n",
    "dense1 = tf.layers.dense(flat1, 128, activation=tf.nn.relu)\n",
    "# Now 1*128\n",
    "dense2 = tf.layers.dense(dense1, 64, activation=tf.nn.relu)\n",
    "# Now 1*64\n",
    "final = tf.layers.dense(dense2, 10, activation=tf.nn.softmax)\n",
    "# 1*10\n",
    "\n",
    "one_hot_labs = tf.one_hot(targets_lab_,10)\n",
    "\n",
    "#loss1 = tf.nn.sigmoid_cross_entropy_with_logits(labels=one_hot_labs, logits=final)\n",
    "loss1 = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_labs, logits=final)\n",
    "cost1 = tf.reduce_mean(loss1)\n",
    "opt1 = tf.train.AdamOptimizer(0.001).minimize(cost1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the thing\n",
    "epochs = 3\n",
    "batch_size = 200\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(mnist.train.num_examples//batch_size, \"batches\")\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        imgs = mnist.train.images[ii*batch_size : (ii+1)*batch_size].reshape((-1, 28, 28, 1))\n",
    "        labs = mnist.train.labels[ii*batch_size : (ii+1)*batch_size]\n",
    "        #print(labs.shape)\n",
    "        #imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        batch_cost, _ = sess.run([cost1, opt1], feed_dict={inputs_: imgs,\n",
    "                                                         targets_lab_: labs})\n",
    "\n",
    "        if ii%50==0: print(\"Epoch: {}/{}, batch {}...\".format(e+1, epochs, ii), \n",
    "                           \"Training loss: {:.4f}\".format(batch_cost))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train accuracy\n",
    "train_preds = sess.run(final, feed_dict = {inputs_: mnist.train.images.reshape(-1,28,28,1)})\n",
    "train_preds_cat = [x.argmax() for x in train_preds]\n",
    "sum(train_preds_cat == mnist.train.labels)/len(train_preds_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "test_preds = sess.run(final, feed_dict = {inputs_: mnist.test.images.reshape(-1,28,28,1)})\n",
    "test_preds_cat = [x.argmax() for x in test_preds]\n",
    "sum(test_preds_cat == mnist.test.labels)/len(test_preds_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we compress this?? (specialized framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_train_spec = sess.run(maxpool1, feed_dict = {inputs_: mnist.train.images.reshape(-1,28,28,1)})\n",
    "compressed_test_spec = sess.run(maxpool1, feed_dict = {inputs_: mnist.test.images.reshape(-1,28,28,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_train_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_comp_ = tf.placeholder(tf.float32, (None, 7, 7, 8), name='inputs_comp')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "### Decoder\n",
    "#upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "# Now 7x7x8\n",
    "#conv4 = tf.layers.conv2d(upsample1, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x8\n",
    "#upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "upsample2 = tf.image.resize_nearest_neighbor(inputs_comp_, (14,14))\n",
    "# Now 14x14x8\n",
    "conv5 = tf.layers.conv2d(upsample2, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x8\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "# Now 28x28x8\n",
    "conv6 = tf.layers.conv2d(upsample3, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x16\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding='same', activation=None)\n",
    "#Now 28x28x1\n",
    "\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the thing\n",
    "epochs = 10\n",
    "batch_size = 200\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(mnist.train.num_examples//batch_size, \"batches\")\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        imgs = compressed_train_spec[ii*batch_size : (ii+1)*batch_size]\n",
    "        labs = mnist.train.images[ii*batch_size : (ii+1)*batch_size].reshape((-1, 28, 28, 1))\n",
    "        #print(labs.shape)\n",
    "        #imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_comp_: imgs,\n",
    "                                                         targets_: labs})\n",
    "\n",
    "        if ii%50==0: print(\"Epoch: {}/{}, batch {}...\".format(e+1, epochs, ii), \n",
    "                           \"Training loss: {:.4f}\".format(batch_cost))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "raw_imgs = mnist.test.images[:10]\n",
    "in_imgs = compressed_test_spec[:10]\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_comp_: in_imgs.reshape((10, 7, 7, 8))})\n",
    "\n",
    "for images, row in zip([raw_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
