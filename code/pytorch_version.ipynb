{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assist from: https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #Compress Stuff\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv2b = nn.Conv2d(16, 16, 3)\n",
    "        \n",
    "        #Classify stuff\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        # I don't understand why this asymetric padding makes the numbers work out!\n",
    "        self.pad44 = nn.ZeroPad2d((4,4,4,4))\n",
    "        self.pad34 = nn.ZeroPad2d((3,4,3,4))\n",
    "        self.pad33 = nn.ZeroPad2d((3,3,3,3))\n",
    "        self.pad23 = nn.ZeroPad2d((2,3,2,3))\n",
    "        self.pad22 = nn.ZeroPad2d((2,2,2,2))\n",
    "        self.pad12 = nn.ZeroPad2d((1,2,1,2))\n",
    "        self.pad11 = nn.ZeroPad2d((1,1,1,1)) #Why do I need to use this padding for decompression??\n",
    "        \n",
    "        #Decompress Stuff\n",
    "        \n",
    "        # What's diff between conv2d and convtranspose2d???\n",
    "        #self.conv3 = nn.ConvTranspose2d(8, 16, 3)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 3)\n",
    "        self.conv4 = nn.Conv2d(16, 6, 3)\n",
    "        self.conv5 = nn.Conv2d(6, 1, 3)\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "        #self.drop2d = nn.Dropout2d()\n",
    "        self.drop = nn.Dropout()\n",
    "        \n",
    "    def compress(self, x):\n",
    "        self.size1 = x.size()\n",
    "        #x, self.ind1 = F.max_pool2d(F.relu(self.drop2d(self.conv1(self.pad1(x)))), (2, 2), return_indices = True)\n",
    "        x, self.ind1 = F.max_pool2d(F.relu(self.conv1(self.pad23(x))), (2, 2), return_indices = True)\n",
    "        #self.size2 = x.size()\n",
    "        #print(self.ind1[0][0])\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x, self.ind2 = F.max_pool2d(F.relu(self.conv2(x)), (2, 2), return_indices = True)\n",
    "        #print(self.ind2.shape)\n",
    "        return x\n",
    "        \n",
    "    def classify(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        #x = self.compress(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.drop(self.fc1(x)))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.drop(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def classify_full(self, x):\n",
    "        x = self.compress(x)\n",
    "        return self.classify(x)\n",
    "    \n",
    "    #def classify_full_quantize(self, x):\n",
    "    #    #x = torch.tensor(np.float16(self.compress(x)))\n",
    "    #    x = (self.compress(x)*256).round()/256\n",
    "    #    return self.classify(x)\n",
    "    \n",
    "    def decompress(self, x):\n",
    "        #y = self.conv3(self.pad2(x))\n",
    "        #print(x.shape)\n",
    "        #print(self.size2)\n",
    "        #y = F.max_unpool2d(x, self.ind2, kernel_size = (2,2), output_size=torch.Size([1,8,14,14]))\n",
    "        y = self.upsample(x)\n",
    "        #nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        #print(y.shape)\n",
    "        #print(x.shape)\n",
    "        #x = F.relu(self.drop2d(self.conv3(self.pad2(self.upsample(x)))))\n",
    "        x = F.relu(self.conv3(self.pad22(self.upsample(x))))\n",
    "        x = F.relu(self.conv4(self.pad22(self.upsample(x))))\n",
    "        x = F.sigmoid(self.conv5(self.pad22(x)))\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def ae_full(self, x):\n",
    "        x = self.compress(x)\n",
    "        #print(x.shape)\n",
    "        return self.decompress(x)\n",
    "\n",
    "    #def ae_full_quantize(self, x):\n",
    "    #    x = (self.compress(x)*256).round()/256\n",
    "    #    return self.decompress(x)\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "    #I think 'forward' needs to be defined as the default path in a Net\n",
    "    def forward(self, x):\n",
    "        x = self.compress(x)\n",
    "        return x#self.classify(x)\n",
    "        \n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion_ae = nn.CrossEntropyLoss()\n",
    "criterion_mse = nn.MSELoss()\n",
    "criterion_ae = nn.BCELoss()\n",
    "#Also try BCEWithLogitsLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer_ae = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_test():\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            #outputs = net.classify_full(images)\n",
    "            \n",
    "            comp = net.compress(images).detach().round()\n",
    "            if comp.max() > 15: print(\"WARNING, max compressed int is greater than 15:\", comp.max())\n",
    "            \n",
    "            #print(comp)\n",
    "            outputs = net.classify(comp)\n",
    "            #outputs = net.classify(comp)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = (correct / total)\n",
    "    print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "        100 * accuracy))\n",
    "    \n",
    "    return(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pytorch/examples/blob/master/super_resolution/main.py\n",
    "def ae_test():\n",
    "    avg_psnr = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            #outputs = net.ae_full_quantize(images)\n",
    "            #outputs = net.decompress(torch.tensor(np.float32(np.float16(net.compress(images).detach()))))\n",
    "            comp = net.compress(images).detach().round()\n",
    "            if comp.max() > 15: print(\"WARNING, max compressed int is greater than 15:\", comp.max())\n",
    "            #comp = np.float32(comp)\n",
    "            #outputs = net.decompress(comp)\n",
    "            #print(comp)\n",
    "            outputs = net.decompress(comp)\n",
    "            #outputs = net.decompress(comp.round())\n",
    "            mse = criterion_mse(outputs, images)\n",
    "            psnr = 10 * np.log10(1 / mse.item())\n",
    "            avg_psnr += psnr\n",
    "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 1, 28, 28)\n",
    "out = net.compress(input)\n",
    "print(out.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])#,\n",
    "     #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=512,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.KMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.KMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=512,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:4]))\n",
    "# print labels\n",
    "#print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "print(' '.join('%5s' % str(labels[j].item()) for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(np.float16(images[0]))\n",
    "#1/(2**4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Batch size (1 epoch, re-initialized) --> after AE optimized:\n",
    "\n",
    "8:    92.1%  --> 9.6%\n",
    "\n",
    "16:   92.0%\n",
    "\n",
    "32:   91%  --> 7.8%\n",
    "\n",
    "64:   90.6%\n",
    "\n",
    "128:  89% --> 17.2% --> 88% --> 13.4%\n",
    "\n",
    "256:  84%\n",
    "\n",
    "512:  83.4% --> 57.7% --> 88% --> 44% --> 87.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# five epochs from scratch gives 96% accuracy.\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net.classify_full(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    class_test()\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#83.7  float32\n",
    "#83.6  (1-byte)\n",
    "#83.9  (4-bit)\n",
    "#83.7  (3-bit)\n",
    "#83.7  (2-bit)\n",
    "#83.6  (1-bit)\n",
    "\n",
    "100*np.mean([class_test() for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen version \n",
    "Noticably Faster!\n",
    "AE (9%) --> Frozen (67.6%, 74.7%, 79.5%, 81.2%, 82.8%, 83.7%) --> Full classify (89.5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        #Get \"frozen\" compressed images\n",
    "        with torch.no_grad():\n",
    "            compressed_inputs = net.compress(inputs).detach()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net.classify(compressed_inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    class_test()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images[0:4]))\n",
    "print('GroundTruth: ', ' '.join('%5s' % str(labels[j].item()) for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net.classify_full(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % str(predicted[j].item())\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try alternating on less than a full epoch.\n",
    "\n",
    "# five epochs from scratch gives PSNR of 22 dB\n",
    "\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ae.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net.ae_full(inputs)\n",
    "        loss = criterion_ae(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer_ae.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    ae_test()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15.7298 (same with 1-byte quant)\n",
    "#15.7283 (with 4-bit)\n",
    "#15.7225 (with 3-bit)\n",
    "#?? (with 2-bit)\n",
    "#?? (with 1-bit)\n",
    "\n",
    "\n",
    "\n",
    "ae_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        targets = copy.deepcopy(inputs.detach())\n",
    "        \n",
    "        #Get \"frozen\" compressed images\n",
    "        with torch.no_grad():\n",
    "            compressed_inputs = net.compress(inputs.detach()).detach()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ae.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net.decompress(compressed_inputs)\n",
    "        loss = criterion_ae(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_ae.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images[0:4]))\n",
    "\n",
    "outputs_ae = net.ae_full(images[0:4])\n",
    "imshow(torchvision.utils.make_grid(outputs_ae.detach()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculated PSNR (image recreation quality metric)  (random is roughly 6.4, 17.343 frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  print(sess.run(tf.image.psnr(images[3].numpy(), outputs_ae.detach()[3].numpy(), max_val = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0][0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compress(inputs).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
