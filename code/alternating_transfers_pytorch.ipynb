{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assist from: https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #Compress Stuff\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #self.conv2b = nn.Conv2d(16, 16, 3)\n",
    "        \n",
    "        #Classify stuff\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        # I don't understand why this asymetric padding makes the numbers work out!\n",
    "        self.pad44 = nn.ZeroPad2d((4,4,4,4))\n",
    "        self.pad34 = nn.ZeroPad2d((3,4,3,4))\n",
    "        self.pad33 = nn.ZeroPad2d((3,3,3,3))\n",
    "        self.pad23 = nn.ZeroPad2d((2,3,2,3))\n",
    "        self.pad22 = nn.ZeroPad2d((2,2,2,2))\n",
    "        self.pad12 = nn.ZeroPad2d((1,2,1,2))\n",
    "        self.pad11 = nn.ZeroPad2d((1,1,1,1)) #Why do I need to use this padding for decompression??\n",
    "        \n",
    "        #Decompress Stuff\n",
    "        \n",
    "        # What's diff between conv2d and convtranspose2d???\n",
    "        #self.conv3 = nn.ConvTranspose2d(8, 16, 3)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 3)\n",
    "        self.conv4 = nn.Conv2d(16, 6, 3)\n",
    "        self.conv5 = nn.Conv2d(6, 1, 3)\n",
    "        \n",
    "        #self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "        #self.drop2d = nn.Dropout2d()\n",
    "        self.drop = nn.Dropout()\n",
    "        \n",
    "    def compress(self, x):\n",
    "        self.size1 = x.size()\n",
    "        #x, self.ind1 = F.max_pool2d(F.relu(self.drop2d(self.conv1(self.pad1(x)))), (2, 2), return_indices = True)\n",
    "        x, self.ind1 = F.max_pool2d(F.relu(self.conv1(self.pad23(x))), (2, 2), return_indices = True)\n",
    "        #self.size2 = x.size()\n",
    "        #print(self.ind1[0][0])\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x, self.ind2 = F.max_pool2d(F.relu(self.conv2(x)), (2, 2), return_indices = True)\n",
    "        #print(self.ind2.shape)\n",
    "        return x\n",
    "        \n",
    "    def classify(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        #x = self.compress(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.drop(self.fc1(x)))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.drop(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def classify_full(self, x):\n",
    "        x = self.compress(x)\n",
    "        return self.classify(x)\n",
    "    \n",
    "    #def classify_full_quantize(self, x):\n",
    "    #    #x = torch.tensor(np.float16(self.compress(x)))\n",
    "    #    x = (self.compress(x)*256).round()/256\n",
    "    #    return self.classify(x)\n",
    "    \n",
    "    def decompress(self, x):\n",
    "        #y = self.conv3(self.pad2(x))\n",
    "        #print(x.shape)\n",
    "        #print(self.size2)\n",
    "        #y = F.max_unpool2d(x, self.ind2, kernel_size = (2,2), output_size=torch.Size([1,8,14,14]))\n",
    "        #y = self.upsample(x)\n",
    "        y = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        #nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        #print(y.shape)\n",
    "        #print(x.shape)\n",
    "        #x = F.relu(self.drop2d(self.conv3(self.pad2(self.upsample(x)))))\n",
    "        x = F.relu(self.conv3(self.pad22(F.interpolate(x, scale_factor=2, mode='nearest'))))\n",
    "        x = F.relu(self.conv4(self.pad22(F.interpolate(x, scale_factor=2, mode='nearest'))))\n",
    "        x = torch.sigmoid(self.conv5(self.pad22(x)))\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def ae_full(self, x):\n",
    "        x = self.compress(x)\n",
    "        #print(x.shape)\n",
    "        return self.decompress(x)\n",
    "\n",
    "    #def ae_full_quantize(self, x):\n",
    "    #    x = (self.compress(x)*256).round()/256\n",
    "    #    return self.decompress(x)\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "    #I think 'forward' needs to be defined as the default path in a Net\n",
    "    def forward(self, x):\n",
    "        x = self.compress(x)\n",
    "        return x#self.classify(x)\n",
    "        \n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer1 = optim.Adam(net.parameters())\n",
    "optimizer2 = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion_ae = nn.CrossEntropyLoss()\n",
    "criterion_mse = nn.MSELoss()\n",
    "criterion_ae1 = nn.BCELoss()\n",
    "criterion_ae2 = nn.BCELoss()\n",
    "#Also try BCEWithLogitsLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer_ae1 = optim.Adam(net.parameters())\n",
    "optimizer_ae2 = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_test():\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            #outputs = net.classify_full(images)\n",
    "            \n",
    "            comp = net.compress(images).detach().round()\n",
    "            if comp.max() > 15: print(\"WARNING, max compressed int is greater than 15:\", comp.max())\n",
    "            if comp.max() < 5: print(\"WARNING, max compressed int is small, potential rounding error:\", comp.max())\n",
    "            \n",
    "            #print(comp)\n",
    "            outputs = net.classify(comp)\n",
    "            #outputs = net.classify(comp)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = (correct / total)\n",
    "    print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "        100 * accuracy))\n",
    "    \n",
    "    return(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pytorch/examples/blob/master/super_resolution/main.py\n",
    "def ae_test():\n",
    "    avg_psnr = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            #outputs = net.ae_full_quantize(images)\n",
    "            #outputs = net.decompress(torch.tensor(np.float32(np.float16(net.compress(images).detach()))))\n",
    "            comp = net.compress(images).detach().round()\n",
    "            if comp.max() > 15: print(\"WARNING, max compressed int is greater than 15:\", comp.max())\n",
    "            if comp.max() < 5: print(\"WARNING, max compressed int is small, potential rounding error:\", comp.max())\n",
    "            #comp = np.float32(comp)\n",
    "            #outputs = net.decompress(comp)\n",
    "            #print(comp)\n",
    "            outputs = net.decompress(comp)\n",
    "            #outputs = net.decompress(comp.round())\n",
    "            mse = criterion_mse(outputs, images)\n",
    "            psnr = 10 * np.log10(1 / mse.item())\n",
    "            avg_psnr += psnr\n",
    "\n",
    "    psnr = avg_psnr / len(testloader)\n",
    "    print(\"===> Avg. PSNR: {:.4f} dB\".format(psnr))\n",
    "    \n",
    "    return(psnr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_dig(i):\n",
    "    if i<10: return(\"00\" + str(i))\n",
    "    elif i<100: return(\"0\" + str(i))\n",
    "    else: return(str(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 1, 28, 28)\n",
    "out = net.compress(input)\n",
    "print(out.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])#,\n",
    "     #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#dataset = 'mnist'\n",
    "#dataset = 'kmnist'\n",
    "dataset = 'fashion'\n",
    "\n",
    "if dataset == 'mnist':\n",
    "    dataset_func = torchvision.datasets.MNIST\n",
    "elif dataset == 'kmnist':\n",
    "    dataset_func = torchvision.datasets.KMNIST\n",
    "elif dataset == 'fashion':\n",
    "    dataset_func = torchvision.datasets.FashionMNIST\n",
    "else:\n",
    "    print(\"ERROR: UNKNOWN DATASET\")\n",
    "\n",
    "trainset = dataset_func(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "testset = dataset_func(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=512,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:4]))\n",
    "# print labels\n",
    "#print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "print(' '.join('%5s' % str(labels[j].item()) for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.tensor(np.float16(images[0]))\n",
    "#1/(2**4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Batch size (1 epoch, re-initialized) --> after AE optimized:\n",
    "\n",
    "8:    92.1%  --> 9.6%\n",
    "\n",
    "16:   92.0%\n",
    "\n",
    "32:   91%  --> 7.8%\n",
    "\n",
    "64:   90.6%\n",
    "\n",
    "128:  89% --> 17.2% --> 88% --> 13.4%\n",
    "\n",
    "256:  84%\n",
    "\n",
    "512:  83.4% --> 57.7% --> 88% --> 44% --> 87.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.load_state_dict(torch.load(\"../models/20190427/ae_mnist_e050.model\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_classification():\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer1.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net.classify_full(inputs)\n",
    "        loss = criterion1(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:\n",
    "            print('[%5d] loss: %.3f' %\n",
    "                  (i + 1, running_loss / 20))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# five epochs from scratch gives 96% accuracy.\n",
    "accuracy = []\n",
    "\n",
    "accuracy += [class_test()]\n",
    "\n",
    "torch.save(net.state_dict(), \"../models/20190428/classify_%s_e000.model\"%(dataset))\n",
    "    \n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    print(\"Epoch\", epoch)\n",
    "    full_classification()\n",
    "            \n",
    "    accuracy += [class_test()]\n",
    "\n",
    "    torch.save(net.state_dict(), \"../models/20190428/classify_%s_e%s.model\"%(dataset, three_dig(epoch+1)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracy[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#83.7  float32\n",
    "#83.6  (1-byte)\n",
    "#83.9  (4-bit)\n",
    "#83.7  (3-bit)\n",
    "#83.7  (2-bit)\n",
    "#83.6  (1-bit)\n",
    "\n",
    "#stdev = 0.3\n",
    "100*np.mean([class_test() for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen version \n",
    "Noticably Faster!\n",
    "AE (9%) --> Frozen (67.6%, 74.7%, 79.5%, 81.2%, 82.8%, 83.7%) --> Full classify (89.5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = images[0:1]\n",
    "#labels = labels[0:1]\n",
    "#compressed_inputs = net.compress(inputs).round().detach()\n",
    "\n",
    "\n",
    "# zero the parameter gradients\n",
    "#optimizer.zero_grad()\n",
    "\n",
    "# forward + backward + optimize\n",
    "#outputs = net.classify(compressed_inputs)\n",
    "#loss = criterion(outputs, labels)\n",
    "#loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compression_only():\n",
    "    #running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        #Get \"frozen\" compressed images\n",
    "        #with torch.no_grad():\n",
    "        compressed_inputs = net.compress(inputs).round().detach()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        #optimizer2.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        #outputs = net.classify(compressed_inputs)\n",
    "        #loss = criterion2(outputs, labels)\n",
    "        #loss.backward()\n",
    "        #optimizer2.step()\n",
    "\n",
    "        # print statistics\n",
    "        #running_loss += loss.item()\n",
    "        #if i % 20 == 19:    # print every 2000 mini-batches\n",
    "        #    print('[%5d] loss: %.3f' %\n",
    "        #          (i + 1, running_loss / 20))\n",
    "        #    running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frozen_classification():\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        #Get \"frozen\" compressed images\n",
    "        #with torch.no_grad():\n",
    "        compressed_inputs = net.compress(inputs).round().detach()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net.classify(compressed_inputs)\n",
    "        loss = criterion2(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%5d] loss: %.3f' %\n",
    "                  (i + 1, running_loss / 20))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.load_state_dict(torch.load(\"../models/20190428/ae_%s_e050.model\"%dataset))\n",
    "\n",
    "class_frozen_accuracy = []\n",
    "\n",
    "class_frozen_accuracy += [class_test()]\n",
    "\n",
    "torch.save(net.state_dict(), \"../models/20190428/ae-classify-frozen_%s_e000.model\"%(dataset))\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    print(\"Epoch\", epoch)\n",
    "    frozen_classification()\n",
    "            \n",
    "    class_frozen_accuracy += [class_test()]\n",
    "\n",
    "    torch.save(net.state_dict(), \"../models/20190428/ae-classify-frozen_%s_e%s.model\"%(dataset, three_dig(epoch+1)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images[0:4]))\n",
    "print('GroundTruth: ', ' '.join('%5s' % str(labels[j].item()) for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net.classify_full(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % str(predicted[j].item())\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_frozen_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(class_frozen_accuracy[10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_ae():\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ae1.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net.ae_full(inputs)\n",
    "        loss = criterion_ae1(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer_ae1.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%5d] loss: %.3f' %\n",
    "                  (i + 1, running_loss / 20))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try alternating on less than a full epoch.\n",
    "\n",
    "# five epochs from scratch gives PSNR of 22 dB\n",
    "\n",
    "accuracy_ae = []\n",
    "\n",
    "accuracy_ae += [ae_test()]\n",
    "\n",
    "torch.save(net.state_dict(), \"../models/20190428/ae_%s_e000.model\"%(dataset))\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    print(\"Epoch\", epoch)\n",
    "    full_ae()\n",
    "            \n",
    "    accuracy_ae += [ae_test()]\n",
    "\n",
    "    torch.save(net.state_dict(), \"../models/20190428/ae_%s_e%s.model\"%(dataset, three_dig(epoch+1)))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracy_ae[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15.7298 (same with 1-byte quant)\n",
    "#15.7283 (with 4-bit)\n",
    "#15.7225 (with 3-bit)\n",
    "#?? (with 2-bit)\n",
    "#?? (with 1-bit)\n",
    "\n",
    "\n",
    "\n",
    "ae_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frozen_ae():\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        targets = copy.deepcopy(inputs.detach())\n",
    "        \n",
    "        #Get \"frozen\" compressed images\n",
    "        compressed_inputs = net.compress(inputs).round().detach()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ae2.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net.decompress(compressed_inputs)\n",
    "        loss = criterion_ae2(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_ae2.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%5d] loss: %.3f' %\n",
    "                  (i + 1, running_loss / 20))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.load_state_dict(torch.load(\"../models/20190428/classify_%s_e050.model\"%dataset))\n",
    "\n",
    "ae_frozen_accuracy = []\n",
    "\n",
    "ae_frozen_accuracy += [ae_test()]\n",
    "\n",
    "torch.save(net.state_dict(), \"../models/20190428/classify-ae-frozen_%s_e000.model\"%(dataset))\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    print(\"Epoch\", epoch)\n",
    "    frozen_ae()\n",
    "\n",
    "    ae_frozen_accuracy += [ae_test()]\n",
    "\n",
    "    torch.save(net.state_dict(), \"../models/20190428/classify-ae-frozen_%s_e%s.model\"%(dataset, three_dig(epoch+1)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images[0:4]))\n",
    "\n",
    "outputs_ae = net.ae_full(images[0:4])\n",
    "imshow(torchvision.utils.make_grid(outputs_ae.detach()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculated PSNR (image recreation quality metric)  (random is roughly 6.4, 17.343 frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  print(sess.run(tf.image.psnr(images[3].numpy(), outputs_ae.detach()[3].numpy(), max_val = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_frozen_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ae_frozen_accuracy[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0][0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compress(inputs).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(\"../models/20190428/ae_%s_e000.model\"%dataset))\n",
    "\n",
    "ae_retrieved_accuracy = []\n",
    "\n",
    "ae_retrieved_accuracy += [ae_test()]\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    print(epoch)\n",
    "    \n",
    "    net.load_state_dict(torch.load(\"../models/20190428/ae_%s_e%s.model\"%(dataset, three_dig(epoch + 1))))\n",
    "\n",
    "    ae_retrieved_accuracy += [ae_test()]\n",
    "\n",
    "print('Finished Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ae_retrieved_accuracy[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_retrieved_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_alt_psnr = []\n",
    "class_alt_acc = []\n",
    "\n",
    "ae_alt_psnr += [ae_test()]\n",
    "class_alt_acc += [class_test()]\n",
    "\n",
    "k_ae = 1\n",
    "j_ae = 1\n",
    "\n",
    "k_class = 1\n",
    "j_class = 1\n",
    "\n",
    "torch.save(net.state_dict(), \"../models/alternating_20190428/alt_%s_e000.model\"%(dataset))\n",
    "\n",
    "for epoch_set in range(25):  # loop over the dataset multiple times\n",
    "\n",
    "    print()\n",
    "    print(\"Round %d of alternating training\"%(epoch_set+1))\n",
    "    \n",
    "    ###  Full AE  ###\n",
    "    print(\"Full AE\")\n",
    "    full_ae()\n",
    "\n",
    "    torch.save(net.state_dict(), \"../models/alternating_20190428/alt_%s_e%s_1aefull.model\"%(dataset, epoch_set+1))\n",
    "    ae_alt_psnr += [ae_test()]\n",
    "    class_alt_acc += [class_test()]\n",
    "            \n",
    "        \n",
    "    ###  Frozen Class  ###\n",
    "    print(\"Classifer only\")\n",
    "    frozen_classification()\n",
    "    \n",
    "    torch.save(net.state_dict(), \"../models/alternating_20190428/alt_%s_e%s_2classfreeze.model\"%(dataset, epoch_set+1))\n",
    "    ae_alt_psnr += [ae_test()]\n",
    "    class_alt_acc += [class_test()]\n",
    "\n",
    "    \n",
    "    ###  Full Class  ###\n",
    "    print(\"Full Classifer\")\n",
    "    full_classification()\n",
    "            \n",
    "    torch.save(net.state_dict(), \"../models/alternating_20190428/alt_%s_e%s_3classfull.model\"%(dataset, epoch_set+1))\n",
    "    ae_alt_psnr += [ae_test()]\n",
    "    class_alt_acc += [class_test()]\n",
    "            \n",
    "            \n",
    "    ###  Frozen AE  ###\n",
    "    print(\"Decompressor Only\")\n",
    "    frozen_ae()\n",
    "            \n",
    "    torch.save(net.state_dict(), \"../models/alternating_20190428/alt_%s_e%s_4aefreeze.model\"%(dataset, epoch_set+1))\n",
    "    ae_alt_psnr += [ae_test()]\n",
    "    class_alt_acc += [class_test()]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_alt_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_alt_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ae_alt_psnr[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(class_alt_acc[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune alternating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.load_state_dict(torch.load(\"../models/alternating_20190428/alt_%s_e25_4aefreeze.model\"%dataset))\n",
    "net.load_state_dict(torch.load(\"../models/alternating_20190428/alt_%s_e25_finalize10.model\"%'kmnist'))\n",
    "\n",
    "class_frozen_accuracy = []\n",
    "\n",
    "class_frozen_accuracy += [class_test()]\n",
    "\n",
    "#torch.save(net.state_dict(), \"../models/20190428/ae-classify-frozen_%s_e000.model\"%(dataset))\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    print(\"Epoch\", (epoch+1))\n",
    "    frozen_classification()\n",
    "            \n",
    "    class_frozen_accuracy += [class_test()]\n",
    "\n",
    "    #torch.save(net.state_dict(), \"../models/alternating_20190428/alt_%s_e25_finalize%d.model\"%(dataset, epoch+1))\n",
    "    torch.save(net.state_dict(), \"../models/alternating_20190428/alt_%s_e25_from_kmnist_class%s.model\"%(dataset, three_dig(epoch+1)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in class_frozen_accuracy: print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.load_state_dict(torch.load(\"../models/alternating_20190428/alt_%s_e25_finalize5.model\"%dataset))\n",
    "net.load_state_dict(torch.load(\"../models/alternating_20190428/alt_%s_e25_finalize10.model\"%'kmnist'))\n",
    "\n",
    "ae_frozen_accuracy = []\n",
    "\n",
    "ae_frozen_accuracy += [ae_test()]\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    print(\"Epoch\", epoch)\n",
    "    frozen_ae() \n",
    "\n",
    "    ae_frozen_accuracy += [ae_test()]\n",
    "\n",
    "    #torch.save(net.state_dict(), \"../models/alternating_20190428/alt_%s_e25_finalize%d.model\"%(dataset, epoch+6))\n",
    "    torch.save(net.state_dict(), \"../models/alternating_20190428/alt_%s_e25_from_kmnist_ae%d.model\"%(dataset, epoch+1))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in ae_frozen_accuracy: print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run times (10 epochs each, MNIST, in sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(10):\n",
    "    frozen_classification()\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Full Classification: 257.5\n",
    "* Frozen Classification: 168.3\n",
    "* Full AE: 1378.7\n",
    "* Frozen AE: 1157.5\n",
    "\n",
    "* Just compression: 92.5\n",
    "* AE inference (ae_test, but on training data): 533.5\n",
    "* Class inference (class_test on train data): 102.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a: Compress Forward    9.5\n",
    "b: Compress Back       9.0  OR 22.1\n",
    "\n",
    "c: Decompress Forward  43.9\n",
    "d: Decompress Back     62.4     (Froz AE - AE Inf)\n",
    "\n",
    "e: Classify Forward    1.1\n",
    "f: Classify Back       6.5      (Froz Class - Class Inf)\n",
    "\n",
    "Full Class:   a + e + f + b =  25.8 sec\n",
    "Froz Class:   a + e + f     =  16.8\n",
    "Compress:     a             =   9.2\n",
    "             (e + f = 7.6)\n",
    "Full AE:      a + c + d + b = 137.9\n",
    "Froz AE:      a + c + d     = 115.8\n",
    "             (c + d = 106.3)\n",
    "             \n",
    "AE inference: a + c         =  53.4\n",
    "Class infer:  a + e         =  10.3\n",
    "             \n",
    "             \n",
    "             \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
